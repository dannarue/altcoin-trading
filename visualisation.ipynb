{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation and Analysis of Altcoins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of notebook\n",
    "### Setup\n",
    "- Imports and constants\n",
    "- Data loading and cleaning (from csvs)\n",
    "\n",
    "### Analysis\n",
    "- Comparison at exchange level \n",
    "    - Number of coins comparison\n",
    "    - Volume of trade comparison\n",
    "    - Close price comparison\n",
    "\n",
    "\n",
    "- Comparison at coin level\n",
    "    - Characterising spikes/drops in trade volume\n",
    "    - Characterising impact of rise/fall/neutral of kline period on future periods\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to data ZIP\n",
    "https://drive.google.com/file/d/1s-vUrrSbxjAhUa3XqFIlZqo8hnw81ztY/view?usp=sharing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing imports\n",
    "import numpy as np # (https://numpy.org/)\n",
    "from scipy import stats # (https://www.scipy.org/)\n",
    "import pandas as pd # (https://pandas.pydata.org/)\n",
    "import math\n",
    "import os\n",
    "from forex_python.converter import CurrencyRates # (https://pypi.org/project/forex-python/)\n",
    "\n",
    "# visualisation imports\n",
    "from matplotlib import pyplot as plt # (https://matplotlib.org/)\n",
    "from matplotlib_venn import venn3 # (https://pypi.org/project/matplotlib-venn/)\n",
    "import seaborn as sns # (https://seaborn.pydata.org/)\n",
    "import prettytable # (https://pypi.org/project/PrettyTable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "DATA_COLLECTED = [\"klines\", \"trades\", \"kline_history\"]\n",
    "EXCHANGES = [\"huobi\", \"kucoin\", \"binance\"]\n",
    "EXCLUDED_COINS = [\"BTCUSDT\", \"ETHUSDT\"]\n",
    "BASE_CURRENCY = \"USD\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loads data from csvs to dictionaries.\n",
    "2. Normalise the data between exchanges\n",
    "    - Change coin names to be regular (uppercase, coin name + base coin e.g. BTCUSD)\n",
    "    - Crop kline data to cover the same time period (same overall start + end time covered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huobi_col_labels = [\"ts\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"amount\"]\n",
    "kucoin_col_labels = [\"start_time\", \"amount\", \"open\", \"close\", \"high\", \"low\", \"volume\"]\n",
    "binance_col_labels = [\"start_time\", \"close_time\", \"open\", \"close\", \"high\", \"low\", \"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData():\n",
    "    def __init__(self, exchange, path_to_folder, metric = None, symbol = None):\n",
    "        self.exchange = exchange\n",
    "        self.metric = metric # if None, load all metrics\n",
    "        self.symbol = symbol # if None, load all symbols\n",
    "        self.path_to_folder = path_to_folder\n",
    "        self.data = self.load_data()\n",
    "    \n",
    "    def _check_if_file_empty(self, file_path):\n",
    "        \"\"\"Checks if a file is empty\"\"\"\n",
    "        return os.stat(file_path).st_size == 0\n",
    "    \n",
    "    def _add_col_labels(self, data, col_labels):\n",
    "        \"\"\"Adds column labels to a dataframe\"\"\"\n",
    "        data.columns = col_labels\n",
    "        return data\n",
    "\n",
    "    def _load_data(self, metric, path_to_folder):\n",
    "        \"\"\"Loads data from csv files into a dictionary of dataframes\"\"\"\n",
    "        data = {}\n",
    "        if self.symbol is None:\n",
    "            # for every csv file in the folder, load it into a dataframe\n",
    "            for file in os.listdir(\"{path_to_folder}/{exchange}/{metric}\".format(path_to_folder=path_to_folder, exchange=self.exchange, metric=metric)):\n",
    "                # get the symbol from the csv file name\n",
    "                symbol = file.split(\".\")[0]\n",
    "                # check not empty\n",
    "                if self._check_if_file_empty(f\"{path_to_folder}/{self.exchange}/{metric}/{symbol}.csv\"):\n",
    "                    continue\n",
    "                # load the csv file into a dataframe\n",
    "                data[symbol] = pd.read_csv(f\"{path_to_folder}/{self.exchange}/{metric}/{symbol}.csv\")\n",
    "        else:\n",
    "            data[self.symbol] = pd.read_csv(f\"{path_to_folder}/{metric}/{self.symbol}.csv\")\n",
    "        # add column labels\n",
    "        if self.exchange == \"huobi\":\n",
    "            for symbol in data:\n",
    "                data[symbol] = self._add_col_labels(data[symbol], huobi_col_labels)\n",
    "        elif self.exchange == \"kucoin\":\n",
    "            for symbol in data:\n",
    "                data[symbol] = self._add_col_labels(data[symbol], kucoin_col_labels)\n",
    "        elif self.exchange == \"binance\":\n",
    "            for symbol in data:\n",
    "                data[symbol] = self._add_col_labels(data[symbol], binance_col_labels)\n",
    "        return data\n",
    "\n",
    "\n",
    "    def load_data(self, path_to_folder = None):\n",
    "        \"\"\"Loads data from csv files into a dictionary of dataframes\"\"\"\n",
    "        if path_to_folder is None:\n",
    "            path_to_folder = self.path_to_folder\n",
    "        \n",
    "        data = {}\n",
    "        if self.metric is None:\n",
    "            for metric in DATA_COLLECTED:\n",
    "                data[metric] = self._load_data(metric, path_to_folder)\n",
    "        else:\n",
    "            data[self.metric] = self._load_data(self.metric, path_to_folder)\n",
    "        return data\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormaliseDataFactory():\n",
    "    def __init__(self, exchange: str, data: dict, metric: str, symbol: str = None):\n",
    "        self.exchange = exchange\n",
    "        self.metric = metric\n",
    "        self.symbol = symbol\n",
    "        self.data = data\n",
    "    \n",
    "    def normalise_data(self):\n",
    "        if self.exchange == \"huobi\":\n",
    "            return NormaliseHuobiData(self.exchange, self.data, self.metric, self.symbol).get_normalised_data()\n",
    "        elif self.exchange == \"kucoin\":\n",
    "            return NormaliseKucoinData(self.exchange, self.data, self.metric, self.symbol).get_normalised_data()\n",
    "        elif self.exchange == \"binance\":\n",
    "            return NormaliseBinanceData(self.exchange, self.data, self.metric, self.symbol).get_normalised_data()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "class NormaliseData():\n",
    "    def __init__(self, exchange: str, data: dict, metric: str, symbol: str):\n",
    "        self.exchange = exchange\n",
    "        self.data = data\n",
    "        self.metric = metric\n",
    "        self.symbol = symbol\n",
    "        self.normalised_data = self.normalise_data()\n",
    "\n",
    "    def _normalise_data(self, data: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "    def _normalise_symbol(self, symbol: str):\n",
    "        pass\n",
    "\n",
    "    def _convert_timestamp(self, data: pd.DataFrame):\n",
    "        pass\n",
    "    \n",
    "    def normalise_data(self):\n",
    "        pass\n",
    "\n",
    "    def get_normalised_data(self):\n",
    "        return self.normalised_data\n",
    "    \n",
    "    def get_normalised_data_as_df(self):\n",
    "        return pd.DataFrame(self.normalised_data)\n",
    "    \n",
    "\n",
    "class NormaliseHuobiData(NormaliseData):\n",
    "    def __init__(self, exchange: str, data: dict, metric: str, symbol: str):\n",
    "        super().__init__(exchange, data, metric, symbol)\n",
    "\n",
    "    def normalise_data(self):\n",
    "        normalised_data = {}\n",
    "        for symbol in self.data.keys():\n",
    "            new_symbol = self._normalise_symbol(symbol)\n",
    "            normalised_data[new_symbol] = self._normalise_data(self.data[symbol])\n",
    "        return normalised_data\n",
    "    \n",
    "    def _normalise_symbol(self, symbol: str):\n",
    "        # remove kline interval from symbol\n",
    "        symbol = symbol.split(\"_\")[0]\n",
    "        # uppercase symbol\n",
    "        symbol = symbol.upper()\n",
    "        return symbol\n",
    "\n",
    "    def _normalise_data(self, data: pd.DataFrame):\n",
    "        data.columns = huobi_col_labels\n",
    "        \n",
    "        # convert timestamp to datetime\n",
    "        data[\"ts\"] = pd.to_datetime(data[\"ts\"], unit=\"s\")\n",
    "        # convert all other columns to float\n",
    "        data[\"open\"] = data[\"open\"].astype(float)\n",
    "        data[\"high\"] = data[\"high\"].astype(float)\n",
    "        data[\"low\"] = data[\"low\"].astype(float)\n",
    "        data[\"close\"] = data[\"close\"].astype(float)\n",
    "        data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "        data[\"amount\"] = data[\"amount\"].astype(float)\n",
    "        return data\n",
    "    \n",
    "    def _convert_timestamp(self, data: pd.DataFrame):\n",
    "        # example valid timestamp: 1675843200000\n",
    "        # example invalid timestamp: 1678752000\n",
    "        # pad to 13 digits\n",
    "        data[\"ts\"] = data[\"ts\"].apply(lambda x: x * 1000 if len(str(x)) == 10 else x)\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "class NormaliseKucoinData(NormaliseData):\n",
    "    def __init__(self, exchange: str, data: dict, metric: str, symbol: str):\n",
    "        super().__init__(exchange, data, metric, symbol)\n",
    "\n",
    "    def normalise_data(self):\n",
    "        normalised_data = {}\n",
    "        for symbol in self.data.keys():\n",
    "            new_symbol = self._normalise_symbol(symbol)\n",
    "            normalised_data[new_symbol] = self._normalise_data(self.data[symbol])\n",
    "        return normalised_data\n",
    "    \n",
    "    def _normalise_symbol(self, symbol: str):\n",
    "        # remove kline interval from symbol\n",
    "        symbol = symbol.split(\"_\")[0]\n",
    "        # remove hyphen\n",
    "        symbol = symbol.replace(\"-\", \"\")\n",
    "        # uppercase symbol\n",
    "        symbol = symbol.upper()\n",
    "        return symbol\n",
    "    \n",
    "    def _normalise_data(self, data: pd.DataFrame):\n",
    "        data.columns = kucoin_col_labels\n",
    "        #kucoin_col_labels = [\"start_time\", \"open\", \"close\", \"high\", \"low\", \"volume\", \"amount\"]\n",
    "\n",
    "        # pad start and close times to 13 digits\n",
    "        #data = self._convert_timestamp(data)\n",
    "\n",
    "        # convert timestamp to datetime\n",
    "        data[\"start_time\"] = pd.to_datetime(data[\"start_time\"], unit=\"s\")\n",
    "        data[\"open\"] = data[\"open\"].astype(float)\n",
    "        data[\"high\"] = data[\"high\"].astype(float)\n",
    "        data[\"low\"] = data[\"low\"].astype(float)\n",
    "        data[\"close\"] = data[\"close\"].astype(float)\n",
    "        data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "        data[\"amount\"] = data[\"amount\"].astype(float)\n",
    "\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def _convert_timestamp(self, data: pd.DataFrame):\n",
    "        # example valid timestamp: 1675843200000\n",
    "        # example invalid timestamp: 1679425200\n",
    "        # convert from 10 (seconds) to 13 (milliseconds) digits\n",
    "        data[\"start_time\"] = data[\"start_time\"].apply(lambda x: x * 1000 if len(str(x)) == 10 else x)\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "class NormaliseBinanceData(NormaliseData):\n",
    "    def __init__(self, exchange: str, data: dict, metric: str, symbol: str):\n",
    "        super().__init__(exchange, data, metric, symbol)\n",
    "\n",
    "    def normalise_data(self):\n",
    "        normalised_data = {}\n",
    "        for symbol in self.data.keys():\n",
    "            new_symbol = self._normalise_symbol(symbol)\n",
    "            normalised_data[new_symbol] = self._normalise_data(self.data[symbol])\n",
    "        return normalised_data\n",
    "    \n",
    "    def _normalise_symbol(self, symbol: str):\n",
    "        # remove kline interval from symbol\n",
    "        symbol = symbol.split(\"_\")[0]\n",
    "        # remove hyphen\n",
    "        symbol = symbol.replace(\"-\", \"\")\n",
    "        # uppercase symbol\n",
    "        symbol = symbol.upper()\n",
    "        return symbol\n",
    "    \n",
    "    def _normalise_data(self, data: pd.DataFrame):\n",
    "        data.columns = binance_col_labels\n",
    "        #binance_col_labels = [\"start_time\", \"close_time\", \"open\", \"close\", \"high\", \"low\", \"volume\"]\n",
    "\n",
    "        # convert timestamp to datetime\n",
    "        data[\"start_time\"] = pd.to_datetime(data[\"start_time\"], unit=\"ms\")\n",
    "        data[\"close_time\"] = pd.to_datetime(data[\"close_time\"], unit=\"ms\")\n",
    "        data[\"open\"] = data[\"open\"].astype(float)\n",
    "        data[\"high\"] = data[\"high\"].astype(float)\n",
    "        data[\"low\"] = data[\"low\"].astype(float)\n",
    "        data[\"close\"] = data[\"close\"].astype(float)\n",
    "        data[\"volume\"] = data[\"volume\"].astype(float)\n",
    "        return data\n",
    "\n",
    "time_col_by_exchange = {\n",
    "    \"huobi\": \"ts\",\n",
    "    \"binance\": \"start_time\",\n",
    "    \"kucoin\": \"start_time\"\n",
    "}\n",
    "\n",
    "class FilterData():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def filter_data_to_same_timeframe(self, data: dict):\n",
    "        # get symbol with latest first timestamp\n",
    "        # and earliest last timestamp\n",
    "        \"\"\"\n",
    "        latest_start_time = pd.Timestamp(0)\n",
    "        for exchange in data.keys():\n",
    "            index = time_col_by_exchange[exchange]\n",
    "            for symbol in data[exchange].keys():\n",
    "                if data[exchange][symbol][index].iloc[0] > latest_start_time:\n",
    "                    latest_start_time = data[exchange][symbol][index].iloc[0]\n",
    "        \n",
    "        earliest_end_time = pd.Timestamp.now()\n",
    "        for exchange in data.keys():\n",
    "            index = time_col_by_exchange[exchange]\n",
    "            for symbol in data[exchange].keys():\n",
    "                if data[exchange][symbol][index].iloc[-1] < earliest_end_time:\n",
    "                    earliest_end_time = data[exchange][symbol][index].iloc[-1]\n",
    "\n",
    "        # filter data to same timeframe\n",
    "        for exchange in data.keys():\n",
    "            index = time_col_by_exchange[exchange]\n",
    "            for symbol in data[exchange].keys():\n",
    "                for i, row in data[exchange][symbol].iterrows():\n",
    "                    if row[index] < latest_start_time or row[index] > earliest_end_time:\n",
    "                        data[exchange][symbol] = data[exchange][symbol].drop(i)\n",
    "        print(data)\n",
    "        \"\"\"\n",
    "        return data\n",
    "    \n",
    "    def filter_excluded_coins(self, data: dict, excluded_coins: list):\n",
    "        for exchange in data.keys():\n",
    "            for symbol in excluded_coins:\n",
    "                # key will not only be symbol, but also kline interval\n",
    "                # so need to check if symbol is in key\n",
    "                if symbol in data[exchange].keys():\n",
    "                    del data[exchange][symbol]\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Normalise currencies\n",
    "Each coin has a different base currency, e.g. BTC, ETH, USDT\n",
    "We want to normalise all coins to the same base currency - USD\n",
    "\"\"\"\n",
    "\n",
    "class NormaliseCurrencies():\n",
    "    def __init__(self, exchange: str, data: dict, base_currency = \"USD\"):\n",
    "        self.exchange = exchange\n",
    "        self.data = data\n",
    "        self.base_currency = base_currency\n",
    "        self.fiat_currencies = self._get_fiat_currencies()\n",
    "        self.norm_data = {}\n",
    "\n",
    "    def normalise_currencies(self):\n",
    "        for symbol in self.data.keys():\n",
    "            self.norm_data[symbol] = self._normalise_currency(symbol)\n",
    "        return self.norm_data\n",
    "    \n",
    "    def _get_fiat_currencies(self):\n",
    "        # get list of fiat currencies\n",
    "        c = CurrencyRates()\n",
    "        return c.get_rates(\"USD\").keys()\n",
    "    \n",
    "    def _get_fiat_price(self, currency: str, time: pd.Timestamp):\n",
    "        # get price of fiat currency in base currency\n",
    "        c = CurrencyRates()\n",
    "        try:\n",
    "            return c.get_rate(currency, self.base_currency, time)\n",
    "        except:\n",
    "            return c.get_rate(currency, self.base_currency)\n",
    "        \n",
    "    def _get_coin_price(self, currency: str, time: pd.Timestamp):\n",
    "        # convert the coin into other coins until we reach BTCUSD\n",
    "        # then convert to base currency\n",
    "        \n",
    "        # append USD to symbol and check if it exists\n",
    "        symbol = currency + \"USD\"\n",
    "        if symbol in self.data.keys():\n",
    "            return self.data[symbol][\"close\"][time]\n",
    "        # otherwise check common pairs\n",
    "        pairs = [\"BTC\", \"ETH\", \"USDT\"]\n",
    "        for pair in pairs:\n",
    "            # append pair to symbol and check if it exists\n",
    "            symbol = currency + pair\n",
    "            if symbol in self.data.keys():\n",
    "                # get price of pair in base currency\n",
    "                if pair == self.base_currency:\n",
    "                    price = 1\n",
    "                else:\n",
    "                    price = self._get_price(pair, time)\n",
    "                # get price of coin in pair\n",
    "                coin_price = self.data[symbol][\"close\"][time]\n",
    "                # return price of coin in base currency\n",
    "                return coin_price * price\n",
    "        # if no pairs found, return 0\n",
    "        return 0\n",
    "    \n",
    "    def _get_price(self, currency: str, time: pd.Timestamp):\n",
    "        # the currency can either be a fiat currency or a coin\n",
    "        # if fiat, use forex-python to get price\n",
    "        # if coin, use ccxt to get price\n",
    "        if currency in self.fiat_currencies:\n",
    "            price = self._get_fiat_price(currency, time)\n",
    "        else:\n",
    "            price = self._get_coin_price(currency, time)\n",
    "        return price\n",
    "\n",
    "    \n",
    "    def _normalise_currency(self, symbol: str):\n",
    "        # get currency of symbol\n",
    "        currency = symbol[-3:]\n",
    "        # get symbol without currency\n",
    "        symbol = symbol[:-3]\n",
    "        # get price of symbol in base currency\n",
    "        if currency == self.base_currency:\n",
    "            price = 1\n",
    "        else:\n",
    "            price = self._get_price(symbol, currency)\n",
    "        # normalise data\n",
    "        data = self.data[symbol]\n",
    "        data[\"open\"] = data[\"open\"] * price\n",
    "        data[\"high\"] = data[\"high\"] * price\n",
    "        data[\"low\"] = data[\"low\"] * price\n",
    "        data[\"close\"] = data[\"close\"] * price\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kline data\n",
    "huobi_data = LoadData(exchange=\"huobi\", path_to_folder=DATA_PATH, metric=\"kline_history\").get_data()\n",
    "kucoin_data = LoadData(exchange=\"kucoin\", path_to_folder=DATA_PATH, metric=\"kline_history\").get_data()\n",
    "binance_data = LoadData(exchange=\"binance\", path_to_folder=DATA_PATH, metric=\"kline_history\").get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "huobi_normalised_data = NormaliseDataFactory(exchange=\"huobi\", metric=\"kline_history\", data=huobi_data[\"kline_history\"]).normalise_data()\n",
    "kucoin_normalised_data = NormaliseDataFactory(exchange=\"kucoin\", metric=\"kline_history\", data=kucoin_data[\"kline_history\"]).normalise_data()\n",
    "binance_normalised_data = NormaliseDataFactory(exchange=\"binance\", metric=\"kline_history\", data=binance_data[\"kline_history\"]).normalise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to same timeframe\n",
    "filtered_data = FilterData().filter_data_to_same_timeframe(data={\"huobi\": huobi_normalised_data, \"kucoin\": kucoin_normalised_data, \"binance\": binance_normalised_data})\n",
    "huobi_filtered = filtered_data[\"huobi\"]\n",
    "kucoin_filtered = filtered_data[\"kucoin\"]\n",
    "binance_filtered = filtered_data[\"binance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter excluded coins\n",
    "filtered_data = FilterData().filter_excluded_coins(data={\"huobi\": huobi_filtered, \"kucoin\": kucoin_filtered, \"binance\": binance_filtered}, excluded_coins=EXCLUDED_COINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "merged_data = {\"huobi\": huobi_filtered, \"kucoin\": kucoin_filtered, \"binance\": binance_filtered}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterise Dataset\n",
    "- Number of exchanges\n",
    "- Number of coins (total)\n",
    "- Number of klines (total)\n",
    "- Earliest time and latest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of exchanges\n",
    "num_exchanges = len(merged_data.keys())\n",
    "\n",
    "# get number of coins\n",
    "num_coins = 0\n",
    "for exchange in merged_data.keys():\n",
    "    num_coins += len(merged_data[exchange].keys())\n",
    "\n",
    "# get total number of data points across all exchanges and coins\n",
    "num_data_points = 0\n",
    "for exchange in merged_data.keys():\n",
    "    for symbol in merged_data[exchange].keys():\n",
    "        num_data_points += len(merged_data[exchange][symbol].index)\n",
    "\n",
    "# get number of unique coins\n",
    "unique_coins = []\n",
    "for exchange in merged_data.keys():\n",
    "    for symbol in merged_data[exchange].keys():\n",
    "        if symbol not in unique_coins:\n",
    "            unique_coins.append(symbol)\n",
    "num_unique_coins = len(unique_coins)\n",
    "\n",
    "# minimum number of data points for each coin\n",
    "min_data_points = 1000000\n",
    "for exchange in merged_data.keys():\n",
    "    for symbol in merged_data[exchange].keys():\n",
    "        if len(merged_data[exchange][symbol].index) < min_data_points:\n",
    "            min_data_points = len(merged_data[exchange][symbol].index)\n",
    "\n",
    "# get earliest and latest date for each exchange\n",
    "earliest_date_by_exchange = {\"huobi\": pd.Timestamp(\"now\"), \"kucoin\": pd.Timestamp(\"now\"), \"binance\": pd.Timestamp(\"now\")}\n",
    "latest_date_by_exchange = {\"huobi\": pd.Timestamp(\"1970-01-01\"), \"kucoin\": pd.Timestamp(\"1970-01-01\"), \"binance\": pd.Timestamp(\"1970-01-01\")}\n",
    "\n",
    "def get_earliest_latest_date(dataset: dict, exchange: str):\n",
    "    # get earliest date\n",
    "    earliest_date = pd.Timestamp(\"now\")\n",
    "    latest_date = pd.Timestamp(\"1970-01-01\")\n",
    "    for symbol in dataset[exchange].keys():\n",
    "        if dataset[exchange][symbol][time_col_by_exchange[exchange]][0] < earliest_date:\n",
    "            earliest_date = dataset[exchange][symbol][time_col_by_exchange[exchange]][0]\n",
    "        # get latest date\n",
    "        # indexing to -1 not valid\n",
    "        num_data_points = len(dataset[exchange][symbol][\"open\"])\n",
    "        if dataset[exchange][symbol][time_col_by_exchange[exchange]][num_data_points - 1] > latest_date:\n",
    "            latest_date = dataset[exchange][symbol][time_col_by_exchange[exchange]][num_data_points - 1]\n",
    "    return earliest_date, latest_date\n",
    "\n",
    "for exchange in merged_data.keys():\n",
    "    earliest_date_by_exchange[exchange], latest_date_by_exchange[exchange] = get_earliest_latest_date(merged_data, exchange)\n",
    "\n",
    "# average number of data points per coin\n",
    "avg_num_data_points_per_coin = num_data_points / num_coins\n",
    "\n",
    "\n",
    "print(\"Number of exchanges: {}\".format(num_exchanges))\n",
    "print(\"Number of coins: {}\".format(num_coins))\n",
    "print(\"Number of data points: {}\".format(num_data_points))\n",
    "print(\"Number of unique coins: {}\".format(num_unique_coins))\n",
    "print(\"Average number of data points per coin: {}\".format(avg_num_data_points_per_coin))\n",
    "print(\"Minimum number of data points for each coin: {}\".format(min_data_points))\n",
    "\n",
    "# for each exchange, get earliest and latest date\n",
    "for exchange in merged_data.keys():\n",
    "    print(\"{}: Earliest date: {}\".format(exchange, earliest_date_by_exchange[exchange]))\n",
    "    print(\"{}: Latest date: {}\".format(exchange, latest_date_by_exchange[exchange]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Exchanges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of coins (+ shared coins)\n",
    "- Volume of trade\n",
    "- Close prices of coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_of_coins(data: list):\n",
    "    \"\"\"Plots the number of coins in each exchange\"\"\"\n",
    "    # use seaborn style\n",
    "    sns.set()\n",
    "    num_exchanges = len(data)\n",
    "    plt.bar(EXCHANGES, [len(data[i]) for i in range(num_exchanges)])\n",
    "    plt.title(\"Number of coins in each exchange\")\n",
    "    plt.show()\n",
    "\n",
    "list_data = list(merged_data.values())\n",
    "plot_number_of_coins(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shared coins between exchanges\n",
    "\n",
    "def get_shared_coins(exchange_a_data: list, exchange_b_data: list):\n",
    "    \"\"\"Returns a list of shared coins between two exchanges\"\"\"\n",
    "    shared_coins = []\n",
    "    for coin in exchange_a_data.keys():\n",
    "        if coin in exchange_b_data.keys():\n",
    "            shared_coins.append(coin)\n",
    "    return shared_coins\n",
    "\n",
    "def get_shared_coins_between_exchanges(data: list):\n",
    "    \"\"\"Returns a list of shared coins between all exchanges\"\"\"\n",
    "    shared_coins = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            shared_coins.append(get_shared_coins(data[i], data[j]))\n",
    "    return shared_coins\n",
    "\n",
    "shared_all_three = get_shared_coins_between_exchanges(list_data)\n",
    "shared_huobi_kucoin = get_shared_coins(merged_data[\"huobi\"], merged_data[\"kucoin\"])\n",
    "shared_huobi_binance = get_shared_coins(merged_data[\"huobi\"], merged_data[\"binance\"])\n",
    "shared_kucoin_binance = get_shared_coins(merged_data[\"kucoin\"], merged_data[\"binance\"])\n",
    "\n",
    "print(\"Shared coins between all three exchanges: {}\".format(len(shared_all_three[0])))\n",
    "\n",
    "# Venn diagram of shared coins between exchanges\n",
    "plt.figure(figsize=(5, 5))\n",
    "venn3([set(merged_data[\"huobi\"]), set(merged_data[\"kucoin\"]), set(merged_data[\"binance\"])], set_labels = (\"Huobi\", \"Kucoin\", \"Binance\"))\n",
    "plt.title(\"Shared coins between exchanges\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of volume for each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade volume for each exchange\n",
    "\n",
    "def get_trade_volume(data: dict):\n",
    "    \"\"\"Returns the trade volume of each coin\"\"\"\n",
    "    trade_volume = 0\n",
    "    for coin in data.keys():\n",
    "        if coin not in EXCLUDED_COINS:\n",
    "            trade_volume += data[coin][\"volume\"].sum()\n",
    "    return trade_volume\n",
    "\n",
    "huobi_trade_volume = get_trade_volume(merged_data[\"huobi\"])\n",
    "kucoin_trade_volume = get_trade_volume(merged_data[\"kucoin\"])\n",
    "binance_trade_volume = get_trade_volume(merged_data[\"binance\"])\n",
    "\n",
    "def plot_trade_volume(data: dict, title: str = \"Trade volume for each exchange\"):\n",
    "    \"\"\"Plots the trade volume of each coin\"\"\"\n",
    "    plt.bar(data.keys(), data.values())\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "aggregated_vols = {\"Huobi\": huobi_trade_volume, \"Kucoin\": kucoin_trade_volume, \"Binance\": binance_trade_volume}\n",
    "plot_trade_volume(aggregated_vols)\n",
    "\n",
    "# Plot average trade volume per coin for each exchange\n",
    "huobi_avg_vol = huobi_trade_volume / len(merged_data[\"huobi\"])\n",
    "kucoin_avg_vol = kucoin_trade_volume / len(merged_data[\"kucoin\"])\n",
    "binance_avg_vol = binance_trade_volume / len(merged_data[\"binance\"])\n",
    "\n",
    "avg_vols = {\"Huobi\": huobi_avg_vol, \"Kucoin\": kucoin_avg_vol, \"Binance\": binance_avg_vol}\n",
    "plot_trade_volume(avg_vols, title=\"Average trade volume per coin for each exchange\")\n",
    "\n",
    "# Plot table with top 10 coins by trade volume for each exchange\n",
    "def get_top_coins_by_trade_volume(data: dict, num_coins: int = 10):\n",
    "    \"\"\"Returns a dict of the top coins by trade volume\"\"\"\n",
    "    top_coins = {}\n",
    "    for coin in data.keys():\n",
    "        top_coins[coin] = data[coin][\"volume\"].sum()\n",
    "    top_coins = dict(sorted(top_coins.items(), key=lambda item: item[1], reverse=True)[:num_coins])\n",
    "    return top_coins\n",
    "\n",
    "huobi_top_vol_coins = get_top_coins_by_trade_volume(merged_data[\"huobi\"])\n",
    "kucoin_top_vol_coins = get_top_coins_by_trade_volume(merged_data[\"kucoin\"])\n",
    "binance_top_vol_coins = get_top_coins_by_trade_volume(merged_data[\"binance\"])\n",
    "\n",
    "def plot_table(data: dict, exchange: str, title: str = \"Top 10 coins by trade volume\"):\n",
    "    \"\"\"Plots a table of the top coins by trade volume\"\"\"\n",
    "    # use prettytable to print table\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Coin\", \"Trade volume\", \"Average price\"]\n",
    "    for coin in data.keys():\n",
    "        table.add_row([coin, data[coin], merged_data[exchange][coin][\"close\"].mean()])\n",
    "    print(title)\n",
    "    print(table)\n",
    "\n",
    "#plot_table(huobi_top_vol_coins, \"huobi\",  title=\"Top 10 coins by trade volume on Huobi\")\n",
    "#plot_table(kucoin_top_vol_coins, \"kucoin\", title=\"Top 10 coins by trade volume on Kucoin\")\n",
    "#plot_table(binance_top_vol_coins, \"binance\", title=\"Top 10 coins by trade volume on Binance\")\n",
    "\n",
    "# plot total trade volume for each exchange, log scale\n",
    "def plot_total_trade_volume(data: dict, title: str = \"Total trade volume for each exchange\"):\n",
    "    \"\"\"Plots the total trade volume for each exchange\"\"\"\n",
    "    plt.bar(data.keys(), data.values())\n",
    "    plt.title(title)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Total trade volume per coin (log scale)\")\n",
    "    plt.xlabel(\"Exchange\")\n",
    "    plt.show()\n",
    "\n",
    "total_vols = {\"Huobi\": huobi_trade_volume, \"Kucoin\": kucoin_trade_volume, \"Binance\": binance_trade_volume}\n",
    "plot_total_trade_volume(total_vols)\n",
    "\n",
    "# plot average trade volume for each exchange, log scale\n",
    "def plot_avg_trade_volume(data: dict, title: str = \"Average trade volume for each exchange\"):\n",
    "    \"\"\"Plots the average trade volume for each exchange\"\"\"\n",
    "    plt.bar(data.keys(), data.values())\n",
    "    plt.title(title)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylabel(\"Average trade volume per coin (log scale)\")\n",
    "    plt.xlabel(\"Exchange\")\n",
    "    plt.show()\n",
    "\n",
    "avg_vols = {\"Huobi\": huobi_avg_vol, \"Kucoin\": kucoin_avg_vol, \"Binance\": binance_avg_vol}\n",
    "plot_avg_trade_volume(avg_vols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close prices for each exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of close price for each exchange\n",
    "\n",
    "def plot_histogram(data: list, title: str = \"Histogram of close price for each exchange\"):\n",
    "    \"\"\"Plots a histogram of the close price for each coin in each exchange\"\"\"\n",
    "    # use seaborn to make the histogram look nicer\n",
    "    sns.set()\n",
    "    plt.hist(data)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Close price\")\n",
    "    plt.ylabel(\"Number of coins\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "huobi_close_prices = [merged_data[\"huobi\"][coin][\"close\"].iloc[-1] for coin in merged_data[\"huobi\"].keys()]\n",
    "kucoin_close_prices = [merged_data[\"kucoin\"][coin][\"close\"].iloc[-1] for coin in merged_data[\"kucoin\"].keys()]\n",
    "binance_close_prices = [merged_data[\"binance\"][coin][\"close\"].iloc[-1] for coin in merged_data[\"binance\"].keys()]\n",
    "\n",
    "#plot_histogram(huobi_close_prices, title=\"Huobi\")\n",
    "#plot_histogram(kucoin_close_prices, title=\"Kucoin\")\n",
    "#plot_histogram(binance_close_prices, title=\"Binance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show more detailed histogram of close prices for very low prices\n",
    "# - Not a good analysis as the base prices are in different currencies\n",
    "# - Just for illustration of the huge bar of coins with close price ~0   \n",
    "\n",
    "def filter_high_priced_coins(data: pd.DataFrame, threshold: float):\n",
    "    # remove coins with close price over threshold\n",
    "    new_data = {}\n",
    "    removed = {}\n",
    "    for coin in data.keys():\n",
    "        if data[coin][\"close\"][0] < threshold:\n",
    "            new_data[coin] = data[coin]\n",
    "        else: \n",
    "            removed[coin] = data[coin]\n",
    "    return new_data, removed\n",
    "\n",
    "def create_table_removed_coins(data: pd.DataFrame, threshold: float, exchange: str):\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Coin\", \"Close price\"]\n",
    "    table.title = \"Coins with close price over {} in {}\".format(threshold, exchange)\n",
    "    for coin in data.keys():\n",
    "        table.add_row([coin, data[coin][\"close\"][0]])\n",
    "    print(table)\n",
    "\n",
    "    \n",
    "huobi_low_traded, huobi_removed = filter_high_priced_coins(merged_data[\"huobi\"], 1.0)\n",
    "kucoin_low_traded, kucoin_removed = filter_high_priced_coins(merged_data[\"kucoin\"], 1.0)\n",
    "binance_low_traded, binance_removed = filter_high_priced_coins(merged_data[\"binance\"], 1.0)\n",
    "\n",
    "huobi_low_traded_close_prices = [huobi_low_traded[coin][\"close\"].iloc[-1] for coin in huobi_low_traded.keys()]\n",
    "kucoin_low_traded_close_prices = [kucoin_low_traded[coin][\"close\"].iloc[-1] for coin in kucoin_low_traded.keys()]\n",
    "binance_low_traded_close_prices = [binance_low_traded[coin][\"close\"].iloc[-1] for coin in binance_low_traded.keys()]\n",
    "\n",
    "plot_histogram(huobi_low_traded_close_prices, title=\"Huobi\")\n",
    "plot_histogram(kucoin_low_traded_close_prices, title=\"Kucoin\")\n",
    "plot_histogram(binance_low_traded_close_prices, title=\"Binance\")\n",
    "\n",
    "#create_table_removed_coins(huobi_removed, 1.0, \"Huobi\")\n",
    "#create_table_removed_coins(kucoin_removed, 1.0, \"Kucoin\")\n",
    "#create_table_removed_coins(binance_removed, 1.0, \"Binance\")\n",
    "\n",
    "# plot table with mean, median, std, skew, kurtosis for each exchange\n",
    "def plot_table_stats(data: dict, title: str = \"Statistics for each exchange\"):\n",
    "    \"\"\"Plots a table with mean, median, std, skew, kurtosis for each exchange\"\"\"\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Exchange\", \"Mean\", \"Median\", \"Std\", \"Skew\", \"Kurtosis\"]\n",
    "    for exchange in data.keys():\n",
    "        table.add_row([exchange, data[exchange].mean(), data[exchange].median(), data[exchange].std(), data[exchange].skew(), data[exchange].kurtosis()])\n",
    "    print(title)\n",
    "    print(table)\n",
    "    # print latex table\n",
    "    print(table.get_latex_string())\n",
    "\n",
    "\n",
    "huobi_stats = pd.Series(huobi_close_prices)\n",
    "kucoin_stats = pd.Series(kucoin_close_prices)\n",
    "binance_stats = pd.Series(binance_close_prices)\n",
    "\n",
    "plot_table_stats({\"Huobi\": huobi_stats, \"Kucoin\": kucoin_stats, \"Binance\": binance_stats})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on volume traded per exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average volume per period for each coin on each exchange\n",
    "def get_avg_vol_per_period(dataset: pd.DataFrame):\n",
    "    \"\"\"Returns a list of the average volume traded per period for each coin\"\"\"\n",
    "    avg_vol_per_period = []\n",
    "    for coin in dataset.keys():\n",
    "        avg_vol_per_period.append(dataset[coin][\"volume\"].mean())\n",
    "    return avg_vol_per_period\n",
    "\n",
    "huobi_avg_vol_per_period = get_avg_vol_per_period(merged_data[\"huobi\"])\n",
    "kucoin_avg_vol_per_period = get_avg_vol_per_period(merged_data[\"kucoin\"])\n",
    "binance_avg_vol_per_period = get_avg_vol_per_period(merged_data[\"binance\"])\n",
    "\n",
    "# Plot histogram of average number of trades per period for each coin on each exchange\n",
    "def plot_histogram_avg_vol_per_period(data: dict, title: str = \"Histogram of average number of trades per period for each coin on each exchange\"):\n",
    "    \"\"\"Plots a histogram of the average number of trades per period for each coin on each exchange\"\"\"\n",
    "    # use seaborn to make the histogram look nicer\n",
    "    sns.set()\n",
    "    plt.hist(data)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Average volume per period\")\n",
    "    plt.ylabel(\"Number of coins\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_histogram_avg_vol_per_period(huobi_avg_vol_per_period, title=\"Huobi\")\n",
    "plot_histogram_avg_vol_per_period(kucoin_avg_vol_per_period, title=\"Kucoin\")\n",
    "plot_histogram_avg_vol_per_period(binance_avg_vol_per_period, title=\"Binance\")\n",
    "\n",
    "# plot skew kurtosis and mean for all exchanges in boxplots\n",
    "def plot_boxplot_avg_vol_per_period(data: dict, title: str = \"Boxplot of average volume per period for each coin on each exchange\"):\n",
    "    \"\"\"Plots a boxplot of the average number of trades per period for each coin on each exchange\"\"\"\n",
    "    # use seaborn to make the histogram look nicer\n",
    "    sns.set()\n",
    "    plt.boxplot(data.values())\n",
    "\n",
    "    # logarithmic scale on y axis\n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Exchange\")\n",
    "    plt.ylabel(\"Average volume per period\")\n",
    "    plt.xticks(range(1, len(data.keys())+1), data.keys())\n",
    "\n",
    "    plt.show()\n",
    "     \n",
    "plot_boxplot_avg_vol_per_period({\"Huobi\": huobi_avg_vol_per_period, \"Kucoin\":kucoin_avg_vol_per_period, \"Binance\":binance_avg_vol_per_period}, title=\"Boxplot of average volume per period for each coin on each exchange\")\n",
    "\n",
    "# plot table of mean, std, skew, kurtosis for each exchange\n",
    "def create_table_avg_trades_per_period(data: dict):\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Exchange\", \"Mean\", \"Std\", \"Skew\", \"Kurtosis\"]\n",
    "    table.title = \"Mean, std, skew, kurtosis for average volume traded per period for each coin on each exchange\"\n",
    "    for exchange in data.keys():\n",
    "        table.add_row([exchange, np.mean(data[exchange]), np.std(data[exchange]), stats.skew(data[exchange]), stats.kurtosis(data[exchange])])\n",
    "    print(table)\n",
    "    # display table in latex format\n",
    "    print(table.get_latex_string())\n",
    "    \n",
    "\n",
    "create_table_avg_trades_per_period({\"Huobi\": huobi_avg_vol_per_period, \"Kucoin\":kucoin_avg_vol_per_period, \"Binance\":binance_avg_vol_per_period})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterising drops in trade volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of periods with no trades for each coin on each exchange\n",
    "def plot_histogram_periods_no_trades(data: dict, title: str = \"Histogram of periods with no trades for each coin on each exchange\"):\n",
    "    \"\"\"Plots a histogram of the periods with no trades for each coin on each exchange\"\"\"\n",
    "    # use seaborn to make the histogram look nicer\n",
    "    sns.set()\n",
    "    plt.hist(data)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of periods with no trades\")\n",
    "    plt.ylabel(\"Number of coins\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def get_periods_of_no_trades(data: pd.DataFrame):\n",
    "    \"\"\"Returns a list of the number of periods with no trades for each coin\"\"\"\n",
    "    # .isna() doesn't work -> volume is a float\n",
    "    # need to detect when volume is 0\n",
    "\n",
    "    periods_no_trades = []\n",
    "    for coin in data.keys():\n",
    "        periods_no_trades.append(data[coin][\"volume\"].eq(0).sum())\n",
    "    return periods_no_trades\n",
    "\n",
    "huobi_periods_no_vol = get_periods_of_no_trades(merged_data[\"huobi\"])\n",
    "kucoin_periods_no_vol = get_periods_of_no_trades(merged_data[\"kucoin\"])\n",
    "binance_periods_no_vol = get_periods_of_no_trades(merged_data[\"binance\"])\n",
    "\n",
    "plot_histogram_periods_no_trades(huobi_periods_no_vol, title=\"Huobi\")\n",
    "plot_histogram_periods_no_trades(kucoin_periods_no_vol, title=\"Kucoin\")\n",
    "plot_histogram_periods_no_trades(binance_periods_no_vol, title=\"Binance\")\n",
    "\n",
    "# Show in detail the coins with 0-50 periods with no trades\n",
    "\n",
    "def filter_coins_with_no_trades(data: pd.DataFrame, threshold: int):\n",
    "    # remove coins with close price over threshold\n",
    "    new_data = {}\n",
    "    removed = {}\n",
    "    for coin in data.keys():\n",
    "        if data[coin][\"volume\"].eq(0).sum() < threshold:\n",
    "            new_data[coin] = data[coin]\n",
    "        else: \n",
    "            removed[coin] = data[coin]\n",
    "    return new_data, removed\n",
    "\n",
    "huobi_low_traded, huobi_removed = filter_coins_with_no_trades(merged_data[\"huobi\"], 50)\n",
    "kucoin_low_traded, kucoin_removed = filter_coins_with_no_trades(merged_data[\"kucoin\"], 50)\n",
    "binance_low_traded, binance_removed = filter_coins_with_no_trades(merged_data[\"binance\"], 50)\n",
    "\n",
    "huobi_low_traded_periods_no_vol = get_periods_of_no_trades(huobi_low_traded)\n",
    "kucoin_low_traded_periods_no_vol = get_periods_of_no_trades(kucoin_low_traded)\n",
    "binance_low_traded_periods_no_vol = get_periods_of_no_trades(binance_low_traded)\n",
    "\n",
    "#plot_histogram_periods_no_trades(huobi_low_traded_periods_no_vol, title=\"Huobi (0-50 periods with no trades))\")\n",
    "#plot_histogram_periods_no_trades(kucoin_low_traded_periods_no_vol, title=\"Kucoin (0-50 periods with no trades))\")\n",
    "#plot_histogram_periods_no_trades(binance_low_traded_periods_no_vol, title=\"Binance (0-50 periods with no trades))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show in detail the coins with 0-10 periods with no trades\n",
    "\n",
    "huobi_low_traded, huobi_removed = filter_coins_with_no_trades(merged_data[\"huobi\"], 10)\n",
    "kucoin_low_traded, kucoin_removed = filter_coins_with_no_trades(merged_data[\"kucoin\"], 10)\n",
    "binance_low_traded, binance_removed = filter_coins_with_no_trades(merged_data[\"binance\"], 10)\n",
    "\n",
    "huobi_low_traded_periods_no_vol = get_periods_of_no_trades(huobi_low_traded)\n",
    "kucoin_low_traded_periods_no_vol = get_periods_of_no_trades(kucoin_low_traded)\n",
    "binance_low_traded_periods_no_vol = get_periods_of_no_trades(binance_low_traded)\n",
    "\n",
    "#plot_histogram_periods_no_trades(huobi_low_traded_periods_no_vol, title=\"Huobi (0-10 periods with no trades))\")\n",
    "#plot_histogram_periods_no_trades(kucoin_low_traded_periods_no_vol, title=\"Kucoin (0-10 periods with no trades))\")\n",
    "#plot_histogram_periods_no_trades(binance_low_traded_periods_no_vol, title=\"Binance (0-10 periods with no trades))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot table of mean, median, std, skew, kurtosis for each exchange\n",
    "def create_table_periods_no_trades(data: dict):\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Exchange\", \"Mean\", \"Median\", \"Std\", \"Skew\", \"Kurtosis\"]\n",
    "    table.title = \"Mean, median, std, skew, kurtosis for periods with no trades for each coin on each exchange\"\n",
    "    for exchange in data.keys():\n",
    "        table.add_row([exchange, np.mean(data[exchange]), np.median(data[exchange]), np.std(data[exchange]), stats.skew(data[exchange]), stats.kurtosis(data[exchange])])\n",
    "    print(table)\n",
    "    # display table in latex format\n",
    "    print(table.get_latex_string())\n",
    "\n",
    "create_table_periods_no_trades({\"Huobi\": huobi_periods_no_vol, \"Kucoin\":kucoin_periods_no_vol, \"Binance\":binance_periods_no_vol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time of day that periods with no trades occur\n",
    "\n",
    "def get_time_of_day_no_trades(data: pd.DataFrame):\n",
    "    \"\"\"Returns a list of the time of day that periods with no trades occur\"\"\"\n",
    "    # .isna() doesn't work -> volume is a float\n",
    "    # need to detect when volume is 0\n",
    "\n",
    "    time_of_day_no_trades = []\n",
    "    for coin in data.keys():\n",
    "        # if has column \"ts\" then use that, otherwise use \"close_time\"\n",
    "        if \"ts\" in data[coin].columns:\n",
    "            timestamps = data[coin][\"ts\"].loc[data[coin][\"volume\"].eq(0)]\n",
    "        else:\n",
    "            timestamps = data[coin][\"start_time\"].loc[data[coin][\"volume\"].eq(0)]\n",
    "        for timestamp in timestamps:\n",
    "            time_of_day_no_trades.append(timestamp.hour)\n",
    "    \n",
    "    return time_of_day_no_trades\n",
    "\n",
    "huobi_time_of_day_no_trades = get_time_of_day_no_trades(merged_data[\"huobi\"])\n",
    "kucoin_time_of_day_no_trades = get_time_of_day_no_trades(merged_data[\"kucoin\"])\n",
    "binance_time_of_day_no_trades = get_time_of_day_no_trades(merged_data[\"binance\"])\n",
    "\n",
    "def get_day_of_the_week(timestamp: pd.Timestamp):\n",
    "    return timestamp.day_name()\n",
    "\n",
    "def get_day_of_the_week_no_trades(data: pd.DataFrame):\n",
    "    \"\"\"Returns a list of the day of the week that periods with no trades occur\"\"\"\n",
    "    # .isna() doesn't work -> volume is a float\n",
    "    # need to detect when volume is 0\n",
    "\n",
    "    day_of_week_no_trades = []\n",
    "    for coin in data.keys():\n",
    "        # if has column \"ts\" then use that, otherwise use \"close_time\"\n",
    "        if \"ts\" in data[coin].columns:\n",
    "            timestamps = data[coin][\"ts\"].loc[data[coin][\"volume\"].eq(0)]\n",
    "        else:\n",
    "            timestamps = data[coin][\"start_time\"].loc[data[coin][\"volume\"].eq(0)]\n",
    "        for timestamp in timestamps:\n",
    "            day_of_week_no_trades.append(get_day_of_the_week(timestamp))\n",
    "    \n",
    "    return day_of_week_no_trades\n",
    "\n",
    "huobi_day_of_week_no_trades = get_day_of_the_week_no_trades(merged_data[\"huobi\"])\n",
    "kucoin_day_of_week_no_trades = get_day_of_the_week_no_trades(merged_data[\"kucoin\"])\n",
    "binance_day_of_week_no_trades = get_day_of_the_week_no_trades(merged_data[\"binance\"])\n",
    "\n",
    "def plot_bar_chart_day_of_week_no_trades(days_of_the_week: list, exchange: str):\n",
    "    \"\"\"Plots a bar chart of the number of periods with no trades for each day of the week\"\"\"\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    days_of_the_week = pd.Series(days_of_the_week)\n",
    "    days_of_the_week = days_of_the_week.value_counts().reindex(days)\n",
    "    days_of_the_week.plot.bar()\n",
    "    plt.title(exchange + \": number of periods with no trades per day of the week\")\n",
    "    plt.xlabel(\"Day of the week\")\n",
    "    plt.ylabel(\"Number of periods with no trades\")\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_chart_day_of_week_no_trades(huobi_day_of_week_no_trades, \"Huobi\")\n",
    "#plot_bar_chart_day_of_week_no_trades(kucoin_day_of_week_no_trades, \"Kucoin\")\n",
    "plot_bar_chart_day_of_week_no_trades(binance_day_of_week_no_trades, \"Binance\")\n",
    "\n",
    "def plot_variance_day_of_week_no_trades(days_of_the_week : list, exchange: str):\n",
    "    \"\"\"Plot skew and kurtosis of the number of periods with no trades for each day of the week\"\"\"\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    days_of_the_week = pd.Series(days_of_the_week)\n",
    "    days_of_the_week = days_of_the_week.value_counts().reindex(days)\n",
    "    print(exchange + \" variance of periods with no trades per day of the week\")\n",
    "    print(\"Skew: \" + str(days_of_the_week.skew()))\n",
    "    print(\"Kurtosis: \" + str(days_of_the_week.kurtosis()))\n",
    "\n",
    "plot_variance_day_of_week_no_trades(huobi_day_of_week_no_trades, \"Huobi\")\n",
    "#plot_variance_day_of_week_no_trades(kucoin_day_of_week_no_trades, \"Kucoin\")\n",
    "plot_variance_day_of_week_no_trades(binance_day_of_week_no_trades, \"Binance\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterising patterns of rising, falling, or static prices\n",
    "### Approach\n",
    "For each period, track open and close.\n",
    "- If open > close, falling. Check next period and increment category if the next period is rising, falling, or static.\n",
    "- If open < close, rising. Check next period and increment appropriate category.\n",
    "- If open == close, static. Check next period, increment as appropriate.\n",
    "** Improvement: also consider high/low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate coins in huobi and kucoin, keep all in binance\n",
    "# combine all dataframes into aggregated dataframe\n",
    "\n",
    "def remove_duplicate_coins(base_data: pd.DataFrame, data: pd.DataFrame):\n",
    "    \"\"\"Removes duplicate coins from data\"\"\"\n",
    "    # get list of coins in binance\n",
    "    ground = base_data.keys()\n",
    "    # get list of coins in data\n",
    "    data_keys = data.keys()\n",
    "\n",
    "    # remove coins in data that ARE in ground\n",
    "    for coin in ground:\n",
    "        if coin in data_keys:\n",
    "            data.pop(coin)\n",
    "    return data\n",
    "\n",
    "def combine_dataframes(dataframes: dict):\n",
    "    \"\"\"Combines all dataframes into one aggregated dataframe\"\"\"\n",
    "    # get list of coins in binance\n",
    "    ground = dataframes[\"binance\"].keys()\n",
    "\n",
    "    huobi = remove_duplicate_coins(dataframes[\"binance\"], dataframes[\"huobi\"])\n",
    "    kucoin = remove_duplicate_coins(dataframes[\"binance\"], dataframes[\"kucoin\"])\n",
    "    huobi = remove_duplicate_coins(dataframes[\"kucoin\"], dataframes[\"huobi\"])\n",
    "\n",
    "    # combine all dataframes into one\n",
    "    dataframe = pd.DataFrame()\n",
    "    # recall - all dataframes will have different coins and different columns\n",
    "    \n",
    "    # remame ts to start_time\n",
    "    for coin in dataframes[\"binance\"].keys():\n",
    "        dataframes[\"binance\"][coin].rename(columns={\"ts\": \"start_time\"}, inplace=True)\n",
    "    for coin in huobi.keys():\n",
    "        huobi[coin].rename(columns={\"ts\": \"start_time\"}, inplace=True)\n",
    "    for coin in kucoin.keys():\n",
    "        kucoin[coin].rename(columns={\"ts\": \"start_time\"}, inplace=True)\n",
    "\n",
    "    new_columns = [\"start_time\", \"open\", \"high\", \"low\", \"close\", \"volume\"]    \n",
    "    # new dataframe format\n",
    "    # {coin: [{start_time: , open: , high: , low: , close: , volume: }, {start_time: , open: , high: , low: , close: , volume: }, ...], ...}\n",
    "\n",
    "    # concatenate all dataframes\n",
    "    dataframe = pd.concat([dataframes[\"binance\"][coin][new_columns] for coin in ground], keys=ground)\n",
    "    dataframe = pd.concat([dataframe, pd.concat([huobi[coin][new_columns] for coin in huobi.keys()], keys=huobi.keys())])\n",
    "    dataframe = pd.concat([dataframe, pd.concat([kucoin[coin][new_columns] for coin in kucoin.keys()], keys=kucoin.keys())])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "aggregated_data = combine_dataframes(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each coin, track open and close price for each period\n",
    "\n",
    "def check_coin_movement(kline: pd.DataFrame):\n",
    "    \"Returns only if for the input kline, the coin is rising, falling or neutral\"\n",
    "    if kline[\"open\"] > kline[\"close\"]:\n",
    "        return \"fall\"\n",
    "    elif kline[\"open\"] < kline[\"close\"]:\n",
    "        return \"rise\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "def get_coin_movement(data: pd.DataFrame):\n",
    "    \"\"\"Returns a dictionary of coin movements for each coin\"\"\"\n",
    "    coin_movement = {}\n",
    "    coin_rise = {}\n",
    "    coin_fall = {}\n",
    "    coin_neutral = {}\n",
    "    # initialize dictionaries with coin names and 0 values\n",
    "    for coin in data.keys():\n",
    "        coin_movement[coin] = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "        coin_rise[coin] = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "        coin_fall[coin] = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "        coin_neutral[coin] = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "\n",
    "    for coin in data.keys():\n",
    "        coin_movement[coin] = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "        for index, row in data[coin].iterrows():\n",
    "            movement = check_coin_movement(row)\n",
    "            coin_movement[coin][movement] += 1\n",
    "\n",
    "            # if next row exists, check if it is rising, falling or neutral\n",
    "            if index + 1 < len(data[coin]):\n",
    "                next_row = data[coin].iloc[index + 1]\n",
    "                next_movement = check_coin_movement(next_row)\n",
    "                if movement == \"rise\":\n",
    "                    if next_movement == \"rise\":\n",
    "                        coin_rise[coin][\"rise\"] += 1\n",
    "                    elif next_movement == \"fall\":\n",
    "                        coin_rise[coin][\"fall\"] += 1\n",
    "                    else:\n",
    "                        coin_rise[coin][\"neutral\"] += 1\n",
    "                elif movement == \"fall\":\n",
    "                    if next_movement == \"rise\":\n",
    "                        coin_fall[coin][\"rise\"] += 1\n",
    "                    elif next_movement == \"fall\":\n",
    "                        coin_fall[coin][\"fall\"] += 1\n",
    "                    else:\n",
    "                        coin_fall[coin][\"neutral\"] += 1\n",
    "                else:\n",
    "                    if next_movement == \"rise\":\n",
    "                        coin_neutral[coin][\"rise\"] += 1\n",
    "                    elif next_movement == \"fall\":\n",
    "                        coin_neutral[coin][\"fall\"] += 1\n",
    "                    else:\n",
    "                        coin_neutral[coin][\"neutral\"] += 1\n",
    "    return coin_movement, coin_rise, coin_fall, coin_neutral\n",
    "\n",
    "hb_coin_movement, hb_coin_rise, hb_coin_fall, hb_coin_neutral = get_coin_movement(merged_data[\"huobi\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate coin movement for all coins on each exchange\n",
    "def aggregate_coin_movement(coin_movement: dict):\n",
    "    \"\"\"Returns a dictionary of aggregated coin movement for all coins on each exchange\"\"\"\n",
    "    # initialize dictionaries\n",
    "    agg_coin_movement = {\"rise\": 0, \"fall\": 0, \"neutral\": 0}\n",
    "\n",
    "    for coin in coin_movement.keys():\n",
    "        agg_coin_movement[\"rise\"] += coin_movement[coin][\"rise\"]\n",
    "        agg_coin_movement[\"fall\"] += coin_movement[coin][\"fall\"]\n",
    "        agg_coin_movement[\"neutral\"] += coin_movement[coin][\"neutral\"]\n",
    "\n",
    "    return agg_coin_movement\n",
    "\n",
    "hb_agg_coin_movement = aggregate_coin_movement(hb_coin_movement)\n",
    "hb_agg_coin_rise = aggregate_coin_movement(hb_coin_rise)\n",
    "hb_agg_coin_fall = aggregate_coin_movement(hb_coin_fall)\n",
    "hb_agg_coin_neutral = aggregate_coin_movement(hb_coin_neutral)\n",
    "\n",
    "\n",
    "# plot coin movement\n",
    "def plot_coin_movement(coin_movement: dict, title: str):\n",
    "    \"\"\"Plots coin movement\n",
    "    coin_movement: dictionary of coin movement {coin: {rise: , fall: , neutral: }, ...}\n",
    "    \"\"\"\n",
    "    # create a dataframe from coin_movement\n",
    "    df = pd.DataFrame.from_dict(coin_movement, orient=\"index\")\n",
    "    df.plot.bar(title=title)\n",
    "\n",
    "plot_coin_movement(hb_agg_coin_movement, \"Huobi Aggregated Coin Movement\")\n",
    "plot_coin_movement(hb_agg_coin_rise, \"Huobi Aggregated Coin Rise\")\n",
    "plot_coin_movement(hb_agg_coin_fall, \"Huobi Aggregated Coin Fall\")\n",
    "plot_coin_movement(hb_agg_coin_neutral, \"Huobi Aggregated Coin Neutral\")\n",
    "\n",
    "\n",
    "# create table of coin movement\n",
    "def create_coin_movement_table(coin_movement: dict):\n",
    "    \"\"\"Returns a table of coin movement\"\"\"\n",
    "    table = prettytable.PrettyTable()\n",
    "    table.field_names = [\"Coin\", \"Rise\", \"Fall\", \"Neutral\"]\n",
    "    for coin in coin_movement.keys():\n",
    "        table.add_row([coin, coin_movement[coin][\"rise\"], coin_movement[coin][\"fall\"], coin_movement[coin][\"neutral\"]])\n",
    "    return table\n",
    "\n",
    "#hb_coin_movement_table = create_coin_movement_table(hb_coin_movement)\n",
    "#print(hb_coin_movement_table)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
